services:
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.9.2
    container_name: mlflow
    ports:
      - "5000:5000"
    command: >
      mlflow server
      --backend-store-uri sqlite:///mlflow.db
      --default-artifact-root /mlflow/artifacts
      --host 0.0.0.0
      --port 5000
    volumes:
      - ./mlruns:/mlflow

  api:
    build: .
    container_name: inference-api
    ports:
      - "8000:8000"
    environment:
      - MODEL_PATH=/app/models/production/model.joblib
      - MODEL_VERSION=v1
    volumes:
      - ./models/production:/app/models/production
    depends_on:
      - mlflow
